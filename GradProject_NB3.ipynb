{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1> DS200A Computer Vision Assignment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Part Three: Training Models </h2>\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "data_file_1 = Path(\"data/NB_1\", \"cleaned_data.hdf\")\n",
    "data_from_nb1 = pd.read_hdf(data_file_1, \"starting_data\")\n",
    "\n",
    "data_file = Path(\"data/NB_2\", \"cleaned_data.hdf\")\n",
    "full_feature_frame = pd.read_hdf(data_file, \"full_feature\")\n",
    "full_feature_frame['encoding'] = data_from_nb1['encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = (full_feature_frame[['ft'+str(i) for i in range(18)]]).fillna(0)\n",
    "y = full_feature_frame['encoding']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state =42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>  Train models using all of the following methods below. Be sure to drop the actual image column, and the encoding</h3>\tTake note of the differences in accuracy, and methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "The test accuracy is: 27.24\n",
      "The train accuracy is: 27.33\n",
      "The Best parameters are:  {'max_iter': 6500, 'tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_iter': np.arange(4000,7000,500), 'tol':[0.01, 0.001, 0.0001]}\n",
    "clf_lr = clf = GridSearchCV(cv=10, param_grid=parameters, \n",
    "                            estimator=LogisticRegression(random_state=42, solver='lbfgs', \n",
    "                                               multi_class='multinomial')\n",
    "                            , n_jobs=4)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Logistic Regression')\n",
    "print(\"The test accuracy is: %.2f\"%(clf_lr.score(X_test, y_test)*100))\n",
    "print(\"The train accuracy is: %.2f\"%(clf_lr.score(X_train, y_train)*100))\n",
    "print('The Best parameters are: ', clf_lr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 488 tasks      | elapsed:    5.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-nearest Neighbours\n",
      "The test accuracy is: 22.92\n",
      "The train accuracy is: 37.08\n",
      "The Best parameters are:  {'leaf_size': 27, 'n_neighbors': 11, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1200 out of 1200 | elapsed:   13.4s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import neighbors\n",
    "parameters = {'n_neighbors': np.arange(7,12,1), 'leaf_size':np.arange(27, 35, 1), 'p':[1,2,3]}\n",
    "clf_knn = GridSearchCV(cv=10, param_grid=parameters, \n",
    "                            estimator=neighbors.KNeighborsClassifier()\n",
    "                       , n_jobs=4, verbose = True)\n",
    "clf_knn.fit(X_train, y_train)\n",
    "\n",
    "print('K-nearest Neighbours')\n",
    "print(\"The test accuracy is: %.2f\"%(clf_knn.score(X_test, y_test)*100))\n",
    "print(\"The train accuracy is: %.2f\"%(clf_knn.score(X_train, y_train)*100))\n",
    "print('The Best parameters are: ', clf_knn.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=4)]: Done 800 out of 800 | elapsed:  8.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "The test accuracy is: 40.53\n",
      "The train accuracy is: 78.08\n",
      "The Best parameters are:  {'max_depth': 8, 'min_samples_leaf': 8, 'n_estimators': 106}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "parameters = {'n_estimators': np.arange(100,121,6), 'min_samples_leaf':np.arange(8,12,1), 'max_depth': np.arange(7,12,1)}\n",
    "clf_rf = GridSearchCV(cv=10, param_grid=parameters, \n",
    "                          estimator=RandomForestClassifier(criterion='entropy', bootstrap=False,random_state=42)\n",
    "                   , n_jobs=4, verbose=True)\n",
    "\n",
    "clf_rf.fit(X_train,y_train)\n",
    "\n",
    "print('Random Forest')\n",
    "print(\"The test accuracy is: %.2f\"%(clf_rf.score(X_test, y_test)*100))\n",
    "print(\"The train accuracy is: %.2f\"%(clf_rf.score(X_train, y_train)*100))\n",
    "print('The Best parameters are: ', clf_rf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    6.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "The test accuracy is: 24.25\n",
      "The train accuracy is: 42.00\n",
      "The Best parameters are:  {'C': 3, 'gamma': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "parameters = {'gamma':[1e-6,1e-7,1e-8,1e-9], 'C':[1,1.5,2,2.5,3]}\n",
    "clf_svm = GridSearchCV(cv=5, param_grid=parameters, \n",
    "                          estimator=svm.SVC(random_state=42, kernel='rbf')\n",
    "                       , n_jobs=4, verbose=True)\n",
    "clf_svm.fit(X_train,y_train)\n",
    "\n",
    "print('SVM')\n",
    "print(\"The test accuracy is: %.2f\"%(clf_svm.score(X_test, y_test)*100))\n",
    "print(\"The train accuracy is: %.2f\"%(clf_svm.score(X_train, y_train)*100))\n",
    "print('The Best parameters are: ', clf_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation output to:  validation_output_random_forest\n"
     ]
    }
   ],
   "source": [
    "#Read Validation Input\n",
    "val_data_file = Path(\"data/NB_2\", \"val_cleaned_data.hdf\")\n",
    "val_feature_frame = pd.read_hdf(val_data_file, \"val_full_feature\")\n",
    "\n",
    "#Build model using best params found using cross validation\n",
    "clf_rf_final = RandomForestClassifier(n_estimators=106,max_depth=8,min_samples_leaf=8,\n",
    "                                      criterion='entropy', bootstrap=False,random_state=42)\n",
    "#Train final model on entire data\n",
    "clf_rf_final.fit(X,y)\n",
    "# Predict using model\n",
    "res = clf_rf_final.predict(val_feature_frame.fillna(0))\n",
    "\n",
    "#Outputting the to a csv\n",
    "output_file_name = 'validation_output_random_forest'\n",
    "pd.DataFrame(res).to_csv(output_file_name, header=None)\n",
    "print('Saved validation output to: ', output_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
