{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DS200A Computer Vision Assignment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Part Four: Extension Activities</h2>\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow (Optional)- Now, try using TensorFlow to categorize your images. The accuracy should be significantly higher due to the usage of nueral nets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 960 samples, validate on 240 samples\n",
      "Epoch 1/50\n",
      "960/960 [==============================] - 17s 18ms/step - loss: 0.5989 - acc: 0.7519 - val_loss: 0.2454 - val_acc: 0.9500\n",
      "Epoch 2/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.3373 - acc: 0.8834 - val_loss: 0.2358 - val_acc: 0.9500\n",
      "Epoch 3/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.3207 - acc: 0.8986 - val_loss: 0.2343 - val_acc: 0.9500\n",
      "Epoch 4/50\n",
      "960/960 [==============================] - 15s 15ms/step - loss: 0.3019 - acc: 0.9046 - val_loss: 0.2158 - val_acc: 0.9500\n",
      "Epoch 5/50\n",
      "960/960 [==============================] - 15s 15ms/step - loss: 0.2958 - acc: 0.9098 - val_loss: 0.2122 - val_acc: 0.9500\n",
      "Epoch 6/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.2883 - acc: 0.9167 - val_loss: 0.2135 - val_acc: 0.9500\n",
      "Epoch 7/50\n",
      "960/960 [==============================] - 16s 16ms/step - loss: 0.2748 - acc: 0.9208 - val_loss: 0.2037 - val_acc: 0.9500\n",
      "Epoch 8/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.2718 - acc: 0.9244 - val_loss: 0.2220 - val_acc: 0.9500\n",
      "Epoch 9/50\n",
      "960/960 [==============================] - 18s 19ms/step - loss: 0.2624 - acc: 0.9280 - val_loss: 0.1950 - val_acc: 0.9502\n",
      "Epoch 10/50\n",
      "960/960 [==============================] - 25s 26ms/step - loss: 0.2502 - acc: 0.9300 - val_loss: 0.1991 - val_acc: 0.9500\n",
      "Epoch 11/50\n",
      "960/960 [==============================] - 20s 21ms/step - loss: 0.2492 - acc: 0.9350 - val_loss: 0.2123 - val_acc: 0.9504\n",
      "Epoch 12/50\n",
      "960/960 [==============================] - 16s 17ms/step - loss: 0.2378 - acc: 0.9384 - val_loss: 0.1899 - val_acc: 0.9504\n",
      "Epoch 13/50\n",
      "960/960 [==============================] - 16s 16ms/step - loss: 0.2201 - acc: 0.9414 - val_loss: 0.1925 - val_acc: 0.9527\n",
      "Epoch 14/50\n",
      "960/960 [==============================] - 16s 17ms/step - loss: 0.2258 - acc: 0.9396 - val_loss: 0.1981 - val_acc: 0.9525\n",
      "Epoch 15/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.2248 - acc: 0.9425 - val_loss: 0.1853 - val_acc: 0.9513\n",
      "Epoch 16/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.2052 - acc: 0.9445 - val_loss: 0.1814 - val_acc: 0.9542\n",
      "Epoch 17/50\n",
      "960/960 [==============================] - 15s 15ms/step - loss: 0.2137 - acc: 0.9434 - val_loss: 0.1949 - val_acc: 0.9533\n",
      "Epoch 18/50\n",
      "960/960 [==============================] - 15s 15ms/step - loss: 0.2045 - acc: 0.9463 - val_loss: 0.1763 - val_acc: 0.9540\n",
      "Epoch 19/50\n",
      "960/960 [==============================] - 15s 15ms/step - loss: 0.1952 - acc: 0.9470 - val_loss: 0.1857 - val_acc: 0.9540\n",
      "Epoch 20/50\n",
      "960/960 [==============================] - 17s 18ms/step - loss: 0.1958 - acc: 0.9477 - val_loss: 0.1738 - val_acc: 0.9552\n",
      "Epoch 21/50\n",
      "960/960 [==============================] - 16s 17ms/step - loss: 0.1856 - acc: 0.9510 - val_loss: 0.1742 - val_acc: 0.9556\n",
      "Epoch 22/50\n",
      "960/960 [==============================] - 18s 18ms/step - loss: 0.1794 - acc: 0.9514 - val_loss: 0.1720 - val_acc: 0.9554\n",
      "Epoch 23/50\n",
      "960/960 [==============================] - 19s 20ms/step - loss: 0.1703 - acc: 0.9535 - val_loss: 0.1909 - val_acc: 0.9558\n",
      "Epoch 24/50\n",
      "960/960 [==============================] - 17s 18ms/step - loss: 0.1953 - acc: 0.9498 - val_loss: 0.1689 - val_acc: 0.9556\n",
      "Epoch 25/50\n",
      "960/960 [==============================] - 17s 17ms/step - loss: 0.1630 - acc: 0.9534 - val_loss: 0.1863 - val_acc: 0.9565\n",
      "Epoch 26/50\n",
      "960/960 [==============================] - 19s 20ms/step - loss: 0.1790 - acc: 0.9530 - val_loss: 0.1676 - val_acc: 0.9554\n",
      "Epoch 27/50\n",
      "960/960 [==============================] - 17s 18ms/step - loss: 0.1549 - acc: 0.9546 - val_loss: 0.1663 - val_acc: 0.9583\n",
      "Epoch 28/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.1665 - acc: 0.9543 - val_loss: 0.1659 - val_acc: 0.9567\n",
      "Epoch 29/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.1504 - acc: 0.9555 - val_loss: 0.1678 - val_acc: 0.9569\n",
      "Epoch 30/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.1520 - acc: 0.9594 - val_loss: 0.1680 - val_acc: 0.9577\n",
      "Epoch 31/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.1422 - acc: 0.9581 - val_loss: 0.1665 - val_acc: 0.9575\n",
      "Epoch 32/50\n",
      "960/960 [==============================] - 16s 16ms/step - loss: 0.1443 - acc: 0.9596 - val_loss: 0.1681 - val_acc: 0.9556\n",
      "Epoch 33/50\n",
      "960/960 [==============================] - 15s 15ms/step - loss: 0.1433 - acc: 0.9580 - val_loss: 0.1647 - val_acc: 0.9571\n",
      "Epoch 34/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.1377 - acc: 0.9601 - val_loss: 0.1664 - val_acc: 0.9569\n",
      "Epoch 35/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.1326 - acc: 0.9595 - val_loss: 0.1671 - val_acc: 0.9569\n",
      "Epoch 36/50\n",
      "960/960 [==============================] - 15s 15ms/step - loss: 0.1371 - acc: 0.9595 - val_loss: 0.1659 - val_acc: 0.9558\n",
      "Epoch 37/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.1304 - acc: 0.9611 - val_loss: 0.1639 - val_acc: 0.9569\n",
      "Epoch 38/50\n",
      "960/960 [==============================] - 16s 17ms/step - loss: 0.1176 - acc: 0.9615 - val_loss: 0.1698 - val_acc: 0.9575\n",
      "Epoch 39/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.1257 - acc: 0.9635 - val_loss: 0.1657 - val_acc: 0.9560\n",
      "Epoch 40/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.1148 - acc: 0.9632 - val_loss: 0.1663 - val_acc: 0.9556\n",
      "Epoch 41/50\n",
      "960/960 [==============================] - 16s 17ms/step - loss: 0.1163 - acc: 0.9649 - val_loss: 0.1684 - val_acc: 0.9571\n",
      "Epoch 42/50\n",
      "960/960 [==============================] - 18s 19ms/step - loss: 0.1072 - acc: 0.9651 - val_loss: 0.1691 - val_acc: 0.9560\n",
      "Epoch 43/50\n",
      "960/960 [==============================] - 16s 17ms/step - loss: 0.1151 - acc: 0.9657 - val_loss: 0.1667 - val_acc: 0.9563\n",
      "Epoch 44/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.0958 - acc: 0.9689 - val_loss: 0.1839 - val_acc: 0.9550\n",
      "Epoch 45/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.0985 - acc: 0.9658 - val_loss: 0.1840 - val_acc: 0.9556\n",
      "Epoch 46/50\n",
      "960/960 [==============================] - 16s 16ms/step - loss: 0.0951 - acc: 0.9670 - val_loss: 0.1717 - val_acc: 0.9538\n",
      "Epoch 47/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.1276 - acc: 0.9624 - val_loss: 0.1699 - val_acc: 0.9567\n",
      "Epoch 48/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.0888 - acc: 0.9699 - val_loss: 0.1850 - val_acc: 0.9558\n",
      "Epoch 49/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.0842 - acc: 0.9717 - val_loss: 0.1767 - val_acc: 0.9560\n",
      "Epoch 50/50\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.0883 - acc: 0.9711 - val_loss: 0.1748 - val_acc: 0.9550\n",
      "301/301 [==============================] - 2s 5ms/step\n",
      "Accuracy on test data:  0.954817300619081\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from skimage.color import rgb2gray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def TF(X_train,y_train):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(105, 105, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(20))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "    model.fit(X_train,y_train,batch_size=250,epochs=50,verbose=1,validation_split=0.2)\n",
    "    return model\n",
    "\n",
    "#Read data from file\n",
    "data_file = Path(\"data/NB_1\", \"cleaned_data.hdf\")\n",
    "data_from_nb1 = pd.read_hdf(data_file, \"starting_data\")\n",
    "\n",
    "#Tranform into grayscale(as not all images are coloured) and convert it into same size\n",
    "nn_input = data_from_nb1.apply(lambda x: resize(rgb2gray(x['pictures']), (105, 105)), axis=1)\n",
    "X = np.array([list(i.reshape(105,105,1)) for i in nn_input])\n",
    "y = pd.get_dummies(data_from_nb1['encoding'])\n",
    "\n",
    "#Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state =42)\n",
    "\n",
    "#Fit the model\n",
    "model_nn = TF(X_train,y_train)\n",
    "\n",
    "scores = model_nn.evaluate(X_test, y_test)\n",
    "print('Accuracy on test data: ', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output to:  validation_output_neural_network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshaypunhani/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:52: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from skimage import io\n",
    "import glob\n",
    "\n",
    "#Read Validation Input\n",
    "validation_path = '20_Validation/'\n",
    "file_list= os.listdir(validation_path)\n",
    "image_list = [io.imread(validation_path + animal) for animal in file_list if os.path.isfile(validation_path + animal)]\n",
    "validation_df = pd.DataFrame(image_list, columns=['pictures'])\n",
    "\n",
    "#Tranform input\n",
    "val_input = validation_df.apply(lambda x: resize(rgb2gray(x['pictures']), (105, 105)), axis=1)\n",
    "X_val = np.array([list(i.reshape(105,105,1)) for i in val_input])\n",
    "\n",
    "# Predict using model\n",
    "res = model_nn.predict(X_val)\n",
    "\n",
    "#Outputting the to a csv\n",
    "output_file_name = 'validation_output_neural_network'\n",
    "pd.DataFrame(res).apply(lambda x: np.argmax(x), axis=1).to_csv(output_file_name)\n",
    "print('Saved output to: ', output_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
